# NM04-Decisions-Technical_DEC-13.md - DEC-13

# DEC-13: Fast Path Caching

**Category:** Decisions
**Topic:** Technical
**Priority:** ðŸŸ¢ Medium
**Status:** Active
**Date Decided:** 2024-06-12
**Created:** 2025-10-23
**Last Updated:** 2025-10-23

---

## Summary

Cache frequently-called operation routes to bypass dictionary lookups, providing 40% performance improvement for hot operations with automatic enablement after 10 calls.

---

## Context

Gateway routing uses dispatch dictionaries for O(1) lookup, but even O(1) has overhead (~100ns per lookup). Profiling revealed some operations (cache_get, log_info) called hundreds of times per request. Caching the function reference after first few calls could eliminate repeated lookups.

---

## Content

### The Decision

**What We Chose:**
Automatic fast path caching: After 10 calls to an operation, cache the handler function reference to bypass dispatch dictionary lookup.

**Implementation:**
```python
# gateway_core.py
_fast_path_cache = {}
_operation_call_count = {}

def execute_operation(interface, operation, **kwargs):
    # Check fast path cache first
    cache_key = (interface, operation)
    if cache_key in _fast_path_cache:
        handler = _fast_path_cache[cache_key]
        return handler(**kwargs)  # Direct call!
    
    # Normal path: Load interface router
    router = _get_interface_router(interface)
    handler = router.execute_operation(operation, **kwargs)
    
    # Track calls, add to fast path after threshold
    _operation_call_count[cache_key] = _operation_call_count.get(cache_key, 0) + 1
    if _operation_call_count[cache_key] >= 10:
        _fast_path_cache[cache_key] = handler
    
    return handler
```

### Rationale

**Why We Chose This:**

1. **Hot Path Optimization**
   - Some operations called frequently (cache_get ~100x/request)
   - Normal path: 5 function calls + 2 dict lookups = ~150ns
   - Fast path: 3 function calls + 0 dict lookups = ~90ns
   - **Result:** 40% faster for hot operations

2. **Transparent to Users**
   - Automatically enabled (no code changes)
   - No configuration needed
   - Pure optimization
   - Backward compatible
   - **Result:** Free performance gain

3. **Measured Impact**
   - cache_get: 1000ns â†’ 600ns (40% faster)
   - log_info: 800ns â†’ 500ns (38% faster)
   - Minimal memory: ~1KB per cached route
   - **Result:** Significant benefit for minimal cost

4. **Automatic Threshold**
   - 10 calls before caching (avoids one-time operations)
   - Typical hot operations hit threshold quickly
   - Cold operations never cached (no wasted memory)
   - **Result:** Self-optimizing system

### Alternatives Considered

**Alternative 1: Always Use Fast Path**
- **Description:** Cache all operations immediately
- **Pros:** Maximum performance
- **Cons:**
  - Wastes memory on rare operations
  - 100+ operations cached unnecessarily
  - No benefit for operations called once
- **Why Rejected:** Optimize what matters, not everything

**Alternative 2: Manual Fast Path Declaration**
- **Description:** Developer marks operations as "hot"
- **Pros:** Explicit control
- **Cons:**
  - Requires code changes
  - Developer might guess wrong
  - Brittle (hot paths change)
- **Why Rejected:** Automatic better than manual

**Alternative 3: Higher Threshold (100+ calls)**
- **Description:** More conservative caching
- **Pros:** Even less memory usage
- **Cons:**
  - Miss optimization opportunities
  - Many hot operations called 10-50 times
  - Benefit delayed too long
- **Why Rejected:** 10 calls is sweet spot

### Trade-offs

**Accepted:**
- Dictionary memory: ~40 bytes Ã— typical 6 operations = ~240 bytes
- Cached routes don't reflect runtime changes (reload required)
- Slightly more complex gateway code

**Benefits:**
- 40% faster hot operations (measurable)
- Automatic (no developer action needed)
- Minimal memory cost (~240 bytes typical)
- Self-optimizing (adapts to usage)

**Net Assessment:**
240 bytes for 40% performance gain on hot paths is excellent trade-off. The automatic nature means developers get optimization for free.

### Impact

**On Architecture:**
- Introduces caching layer in gateway
- Hot path concept embedded in system
- Demonstrates performance-aware design

**On Development:**
- Developers don't think about fast path
- No code changes needed
- Performance benefit automatic

**On Performance:**
- Hot operations 40% faster
- Typical Lambda: ~6 operations cached
- Memory: 240 bytes (negligible)
- 6+ months: measurable benefit

**On Maintenance:**
- Gateway slightly more complex
- Performance monitoring shows benefit
- No issues in 6+ months

### Future Considerations

**When to Revisit:**
- If memory becomes constrained
- If threshold (10 calls) wrong
- If cached routes cause issues

**Potential Evolution:**
- Adaptive threshold based on memory pressure
- TTL for cached routes (auto-refresh)
- Performance metrics per cached route

**Monitoring Needs:**
- Track fast path hit rate
- Measure performance benefit
- Monitor memory usage

---

## Related Topics

- **DEC-03**: Dispatch dictionary (pattern fast path optimizes)
- **LESS-02**: Measure don't guess (measurement led to this)
- **PATH-01**: Cold start (fast path helps warm execution)

---

## Keywords

fast path, caching, hot operations, performance optimization, automatic optimization, transparent, gateway optimization

---

## Version History

- **2025-10-23**: Migrated to SIMA v3 individual file format
- **2024-06-12**: Original decision documented in NM04-TECHNICAL-Decisions.md

---

**File:** `NM04-Decisions-Technical_DEC-13.md`
**End of Document**
