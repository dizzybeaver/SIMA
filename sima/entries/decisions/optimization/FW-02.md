# FW-02.md

**REF-ID:** FW-02  
**Category:** Decision Logic  
**Subcategory:** Optimization  
**Name:** Optimize or Document Trade-off Framework  
**Priority:** Framework  
**Status:** Active  
**Created:** 2024-10-30  
**Updated:** 2024-10-30

---

## Summary

Framework for deciding between optimizing slow code versus documenting why it's slow, balancing performance gains against code complexity increases.

---

## Problem

Not all slow code should be optimized. Sometimes documenting the performance limitation and explaining the trade-offs is better than adding complexity. Teams need a systematic way to make this decision.

---

## Decision Tree

```
START: Code is slow, considering optimization
│
├─ Measure Parameters:
│  │
│  ├─ G = Performance gain % (if optimized)
│  ├─ C = Complexity increase (1-10 scale)
│  └─ H = Hours to optimize
│
├─ Apply Framework:
│  │
│  ├─ If G > 50% AND C < 3 → OPTIMIZE (clear win)
│  ├─ If G > 30% AND C < 5 → OPTIMIZE (good trade-off)
│  ├─ If G > 20% AND C < 5 → CONSIDER (borderline)
│  ├─ If G < 10% → DOCUMENT (low gain)
│  └─ If C > 7 → DOCUMENT (high complexity)
│
└─ END
```

---

## Examples

### Example 1: Clear Win - Should Optimize

**Scenario:** Hot path function with simple optimization

**Parameters:**
```
Current performance: 100ms
Optimized performance: 50ms
Gain (G): 50% (100ms → 50ms)
Complexity (C): 3/10 (moderate refactoring)
Hours (H): 4
Impact: 20% of total request time
```

**Analysis:**
```
G = 50% (> 30%, excellent)
C = 3 (< 5, acceptable)
H = 4 (reasonable)

Decision: OPTIMIZE
```

**Implementation:**
```python
# Before: O(n²) nested loops
def find_matches(items, targets):
    matches = []
    for item in items:
        for target in targets:
            if item == target:
                matches.append(item)
    return matches

# After: O(n+m) using set
def find_matches(items, targets):
    target_set = set(targets)
    return [item for item in items if item in target_set]

# Result: 100ms → 50ms (50% improvement)
# Complexity: Simple refactoring (C=3)
# Worth it!
```

### Example 2: Should Document

**Scenario:** Cold path function with complex optimization

**Parameters:**
```
Current performance: 50ms
Optimized performance: 40ms
Gain (G): 20% (50ms → 40ms)
Complexity (C): 7/10 (significant refactoring)
Hours (H): 12
Impact: 2% of total request time
```

**Analysis:**
```
G = 20% (borderline)
C = 7 (> 5, high complexity)
H = 12 (significant time)
Impact = 2% (low)

Decision: DOCUMENT
```

**Documentation:**
```python
# PERFORMANCE NOTE: Intentionally O(n²)
# Measured: 50ms for typical input (n=100)
# 
# Why Slow: Nested loop for pattern matching
# Optimization Considered: Could use regex or KMP (40ms, 20% faster)
# 
# Why Not Optimized:
# - Complexity increase: 7/10 (significant)
# - Only 2% of total request time
# - Current code is clear and maintainable
# - Trade-off: 10ms slower but 10x more readable
# 
# Revisit if:
# - Becomes hot path (>100 calls/request)
# - Performance degrades (>100ms)
# - Input size increases (n>500)
# - Simpler optimization discovered
#
# Last measured: 2024-10-30

def pattern_matcher(text, patterns):
    """Find patterns in text (documented trade-off).
    
    Performance: O(n*m) - 50ms typical
    See PERFORMANCE NOTE above for optimization trade-off.
    """
    matches = []
    for pattern in patterns:
        for i in range(len(text) - len(pattern) + 1):
            if text[i:i+len(pattern)] == pattern:
                matches.append((pattern, i))
    return matches
```

### Example 3: Borderline Case

**Scenario:** Medium frequency function, moderate complexity

**Parameters:**
```
Current performance: 80ms
Optimized performance: 60ms
Gain (G): 25% (80ms → 60ms)
Complexity (C): 5/10 (moderate)
Hours (H): 8
Impact: 15% of total request time
```

**Analysis:**
```
G = 25% (> 20%, decent)
C = 5 (at threshold)
H = 8 (moderate)
Impact = 15% (moderate)

Decision: CONSIDER - context dependent
```

**Decision Factors:**
```python
# Factors favoring OPTIMIZE:
# âœ… 15% of total time (significant)
# âœ… 25% performance gain (good)
# âœ… Team has optimization experience

# Factors favoring DOCUMENT:
# âš ï¸ C=5 at threshold
# âš ï¸ 8 hours investment
# âš ï¸ Other higher priority items

# Decision: 
# - If time available → OPTIMIZE
# - If time constrained → DOCUMENT and revisit in 3 months
# - Document either way
```

### Example 4: Complexity Scale Reference

**Understanding Complexity (C) Scale:**

**1-2: Trivial**
```python
# Before: List iteration
result = []
for x in items:
    result.append(x * 2)

# After: List comprehension
result = [x * 2 for x in items]

# Complexity: 1 (trivial improvement)
```

**3-4: Simple**
```python
# Before: Linear search
for item in items:
    if item.id == target_id:
        return item

# After: Dict lookup
items_dict = {item.id: item for item in items}
return items_dict.get(target_id)

# Complexity: 3 (simple data structure change)
```

**5-6: Moderate**
```python
# Before: Sequential processing
for item in items:
    process(item)

# After: Batch processing with cache
cache = {}
batch = []
for item in items:
    if needs_processing(item, cache):
        batch.append(item)
        if len(batch) >= 10:
            process_batch(batch, cache)
            batch = []

# Complexity: 5 (moderate refactoring, new logic)
```

**7-8: Complex**
```python
# Before: Simple synchronous calls
for item in items:
    result = external_api.fetch(item)
    process(result)

# After: Async with connection pooling
async with connection_pool:
    tasks = [fetch_and_process(item) for item in items]
    results = await asyncio.gather(*tasks)

# Complexity: 7 (async/await, connection management, error handling)
```

**9-10: Very Complex**
```
System redesign:
- Multiple file changes
- New architectural patterns
- Breaking changes
- Extensive testing required
- Multi-week effort

Complexity: 9-10 (major refactoring)
```

### Example 5: Decision Matrix Quick Reference

| Gain (G%) | Complexity (C) | Hours (H) | Impact | Decision |
|-----------|----------------|-----------|--------|----------|
| 50% | 2 | 4 | 20% | OPTIMIZE |
| 40% | 4 | 6 | 15% | OPTIMIZE |
| 30% | 3 | 6 | 10% | OPTIMIZE |
| 25% | 5 | 8 | 15% | CONSIDER |
| 20% | 6 | 10 | 10% | DOCUMENT |
| 15% | 4 | 5 | 5% | DOCUMENT |
| 10% | 2 | 2 | 2% | DOCUMENT |
| 5% | 1 | 1 | 1% | DOCUMENT |

**Usage:**
```python
# User asks: "50ms function, can optimize to 40ms, but complex"
# Lookup: G=20%, C=7 → DOCUMENT
# Response: "20% gain but complexity 7 is too high. Document instead."
```

---

## Related Patterns

**Decision Logic:**
- **DT-07**: Should I Optimize This Code (optimization decision tree)
- **DT-10**: Should I Refactor This Code (refactoring decisions)
- **FW-01**: Cache vs Compute Trade-off Framework

**Anti-Patterns:**
- **AP-12**: Premature Optimization (avoid optimizing too early)
- **AP-20**: Unnecessary Complexity (avoid complexity without benefit)

**Lessons:**
- **LESS-02**: Measure First Don't Guess (importance of measurement)
- **LESS-17**: Performance Monitoring Patterns

**Decisions:**
- **DEC-13**: Fast Path Optimization (when to optimize hot paths)

---

## Keywords

optimize vs document, performance trade-off, complexity analysis, code maintainability, technical debt, optimization decision, complexity cost, performance gain analysis

---

## Version History

- **2024-10-30:** Migrated to SIMAv4 format from NM07 v3
- **2024-10-24:** Created in SIMAv3 format

---

**File:** `FW-02.md`  
**Location:** `/sima/entries/decisions/optimization/`  
**End of Document**
