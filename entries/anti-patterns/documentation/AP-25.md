# AP-25.md - Undocumented Decisions

**REF-ID:** AP-25  
**Version:** 1.0.0  
**Category:** Anti-Patterns  
**Topic:** Documentation  
**Priority:** üü† HIGH  
**Status:** Active  
**Created:** 2025-10-30  
**Last Updated:** 2025-10-30

---

## Summary

Making design decisions without documenting the rationale. Future developers don't understand why choices were made, leading to repeated mistakes and architectural decay.

---

## Context

During active development, the reasons for decisions seem obvious. Six months later, those reasons are forgotten, and new developers repeat past mistakes or undo good decisions.

**Problem:** Lost context, repeated mistakes, architectural decay, inability to evolve design.

---

## Content

### The Anti-Pattern

```python
# ‚ùå NO DOCUMENTATION - Why these choices?
def process_batch(items):
    # Why batch size of 100? Why not 50 or 200?
    # Why this specific algorithm?
    # Why not use library X?
    # What were the trade-offs?
    # Nobody knows!
    
    for i in range(0, len(items), 100):
        batch = items[i:i+100]
        process(batch)
```

### Why This Is Dangerous

**1. Lost Context**
```python
# 6 months later
# New dev: "This batch size seems arbitrary, let's increase it"
# Changes 100 ‚Üí 500
# Production: Out of memory errors
# Why? Original developer tested and found 100 was optimal
# Context lost ‚Üí mistake repeated
```

**2. Inability to Evolve**
```python
# 1 year later
# Need to optimize performance
# Questions:
# - Why was this approach chosen?
# - What alternatives were considered?
# - What constraints matter?
# - Can we change it?

# Without documentation:
# - Fear of change (might break something)
# - Must rediscover all trade-offs
# - May make worse decision without context
```

**3. Repeated Mistakes**
```python
# Original dev: "Tried async, caused race conditions, switched to sync"
# Documentation: None
# New dev 1 year later: "Let's make this async for performance!"
# Result: Reintroduces same race conditions
```

### Correct Approach

**Document decisions inline:**
```python
# ‚úÖ DOCUMENTED DECISION
# DECISION: Batch size = 100 items (tested 2024-10-15)
#
# RATIONALE:
# - Tested batch sizes: 10, 50, 100, 200, 500
# - Results:
#   * 10:  Low throughput (too many API calls)
#   * 50:  Better, but still suboptimal
#   * 100: Optimal balance (2.5s per batch, <10MB memory)
#   * 200: Marginal gains (2.3s), 18MB memory (near limit)
#   * 500: Out of memory errors
#
# CONSTRAINTS:
# - Memory limit: 20MB per invocation
# - Timeout: 15 seconds maximum
# - API rate limit: 100 requests/minute
#
# TRADE-OFFS:
# - Larger batches = faster but more memory
# - Smaller batches = safer but slower
# - 100 items balances throughput and reliability
#
# See: Performance test results in docs/performance-2024-10-15.md

BATCH_SIZE = 100

def process_batch(items):
    for i in range(0, len(items), BATCH_SIZE):
        batch = items[i:i+BATCH_SIZE]
        process(batch)
```

**Create decision records:**
```markdown
# docs/decisions/001-batch-processing.md

# ADR 001: Batch Processing Size

## Status
Accepted (2024-10-15)

## Context
Need to process large datasets efficiently while staying within memory and time constraints.

## Decision
Use batch size of 100 items for processing.

## Consequences

### Positive
- Optimal throughput (2.5s per batch)
- Safe memory usage (<10MB per batch)
- Stays within API rate limits
- Predictable performance

### Negative
- May need adjustment if constraints change
- Requires monitoring to detect degradation

### Alternatives Considered
- Batch size 50: Too slow (40% slower)
- Batch size 200: Memory risk, minimal gain
- Dynamic sizing: Added complexity, minimal benefit

## References
- Performance test: docs/performance-2024-10-15.md
- Memory profiling: docs/memory-analysis.md
```

### What to Document

**Architecture decisions:**
```markdown
# Why this pattern?
# Why not alternative X?
# What are the trade-offs?
# What constraints led to this?
```

**Algorithm choices:**
```markdown
# Why this algorithm?
# What's the time/space complexity?
# Why not more common algorithm Y?
# When should we reconsider?
```

**Library choices:**
```markdown
# Why library A over library B?
# What features do we use?
# What limitations does it have?
# When should we reevaluate?
```

**Performance trade-offs:**
```markdown
# What did we optimize for?
# What did we sacrifice?
# What tests informed this?
# What's the measurement methodology?
```

**Security decisions:**
```markdown
# What threats are we protecting against?
# Why this mitigation approach?
# What's the security/usability trade-off?
# When should we review?
```

### Decision Record Template

```markdown
# ADR [NUMBER]: [TITLE]

## Status
[Proposed | Accepted | Deprecated | Superseded by ADR-XXX]

## Context
What is the problem or opportunity?
What constraints exist?
What requirements must be met?

## Decision
What is the change being proposed?
Why this specific solution?

## Consequences

### Positive
What improvements does this bring?

### Negative
What downsides or limitations?

### Risks
What could go wrong?
How do we mitigate?

## Alternatives Considered
What other options were evaluated?
Why were they rejected?

## References
- Related documents
- Test results
- External resources
```

### Where to Document

**1. Code Comments** (short decisions)
```python
# Use binary search - dataset always sorted (DEC-042)
# O(log n) vs O(n) for linear search
result = binary_search(data, target)
```

**2. Module Docstrings** (module-level decisions)
```python
"""
Cache module using LRU eviction (DEC-018).

RATIONALE: LRU balances hit rate and implementation complexity.
Tested against LFU, FIFO, Random. LRU gave 94% hit rate vs
89% for alternatives, with simpler implementation.

See: docs/decisions/018-cache-eviction.md
"""
```

**3. Decision Records** (significant decisions)
```
docs/decisions/
‚îú‚îÄ‚îÄ 001-batch-size.md
‚îú‚îÄ‚îÄ 002-database-choice.md
‚îú‚îÄ‚îÄ 003-api-versioning.md
‚îî‚îÄ‚îÄ README.md  # Index of all decisions
```

**4. Architecture Documents** (system-level decisions)
```
docs/architecture/
‚îú‚îÄ‚îÄ overview.md
‚îú‚îÄ‚îÄ data-flow.md
‚îú‚îÄ‚îÄ security-model.md
‚îî‚îÄ‚îÄ scalability-strategy.md
```

### Maintenance

**Keep decisions up to date:**
```markdown
# Mark as superseded when changed
## Status
Superseded by ADR-052 (2025-03-15)

## Reason for Change
Memory limits increased to 50MB, allowing larger batches.
See ADR-052 for new batch size of 250.
```

**Review periodically:**
```markdown
# Add review reminder
## Next Review
2025-12-01

## Review Criteria
- If memory limits change
- If API rate limits change
- If processing time requirements change
```

---

## Related Topics

- **AP-26**: Stale Comments - Keeping documentation current
- **DEC-19**: Neural Map Documentation - Structured decision capture

---

## Keywords

documentation, decisions, ADR, architecture decision records, rationale, design decisions, technical debt

---

## Version History

- **2025-10-30**: Created - Added ADR template and examples

---

**File:** `AP-25.md`  
**Lines:** ~200  
**End of Document**
